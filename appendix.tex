\section{Appendix}
\subsection{$C^*$-algebras}
Recall the definition of a $C^*$-algebra:
\begin{definition}
A (unital) $C^*$-algebra $A$ is a Banach space over $\mathbb C$ that is also a (unital) algebra such that the multiplication is a bounded bilinear map of norm $1$. It's also supplied with an involution\footnote{An involution has the same properties as the usual conjugation operators. So, $(a+b)^* = a^* + b^*$, $(\lambda a)^* = \lambda^* a^*$, $1^* = 1$, $(ab)^* = b^* a^*$, $(a^*)^* = a$.} $*:A\rightarrow A$ such that $\|a^*a\| = \|a\|^2$ for all $a \in A$. 
\end{definition}
A straightforward\footnote{From the boundedness of the multiplication we obtain $\|a\|^2 = \|a^*a\| \leq \|a^*\|\|a\|$, hence $\|a\| \leq \|a\|^*$. Switching to $a \mapsto a^*$, get $\|a\| = \|a\|^*$. For the unit, $\|1\| = \|1\|^2$ since $1^* = 1$.} consequence from the axioms is that $\|a\| = \|a^*\|$ and in the unital case $\|1\| = 1$.

\subsubsection{Gelfand-Naymark: commutative case}
I think it worth mentioning:
\begin{theorem}
(Gelfand-Naymark, 1st) We have the following:
\begin{enumerate}[(i)]
\item Any possibly non-unital commutative $C^*$-algebra is isomorphic to the space $C_0(\Omega)$ of continuous functions vanishing\footnote{Precisely, a function $\varphi : \Omega \rightarrow \mathbb C$ is vanishing at infinity if for any $\varepsilon >0$ there exists a compact subset $\Delta \subseteq \Omega$ such that $|\phi(t)|< \varepsilon$ when $t \notin \Delta$.} at $\infty$ on some locally compact Hausdorff topological space $\Omega$;
\item Any unital commutative $C^*$-algebra is isomorphic to $C(\Omega)$ for $\Omega$ a compact Hausdorff space.
\end{enumerate}
\end{theorem}

There's an accurate description of both the isomorphism and the space $\Omega$: the space $\Omega$ is the Gelfand spectrum of $A$, and the isomorphism is the Gelfand representation.

Here are the definitions. Let $A$ be a Banach algebra\footnote{I.e. a Banach space that's also an algebra such that the multiplication is a bounded bilinear map with norm $1$.}. Its \emph{Gelfand spectrum} is the space $\Omega \subset A^*$ of all characters\footnote{A character is a non-zero linear functional that preserves the multiplication. It turns out that any character $\chi : A \rightarrow \mathbb C$ has norm $\|\chi\| \leq 1$, so they're automatically continuous, for if $\chi(a) = 1$ for some $a \in A$ with $\|a\| <1$, then let $b:=\sum_{k=1}^\infty a^k$. It follows that $a + ab = b$, hence $1 + \chi(b) = \chi(b)$, which is absurd. } of $A$  that is endowed with $\omega^*$-topology induced from $A^*$. The isomorphism then is the Gelfand representation $\Gamma_A : A \rightarrow C_0(\Omega)$ that sends an element $a \in A$ to a continuous map (vanishing at $\infty$) $\hat a$ such that\footnote{The continuity of $\hat a$ follows right from the definition of $\omega^*$-topology. It indeed vanishes at $\infty$, for $\hat a$ is a continuous map on the compactification $\Omega^\prime := \Omega \cup \{0\}$ such that $\hat{a}(0) = 0$ (look at the formula defining $\hat{a}$), hence for any $\varepsilon > 0$ there's $U_{\varepsilon} \ni 0$ such that $|\hat{a}(\chi)| < \varepsilon$ when $t \in U_{\varepsilon}$. But $U_{\varepsilon}^c$ is compact, as a closed subset of the compact space $\Omega^\prime$, so $\hat a$ vanishes at $\infty$.}
\begin{proposition}
The Gelfand spectrum $\Omega$ of a Banach algebra $A$ is a locally compact Hausdorff space; if $A$ is in addition unital, then $\Omega$ is Hausdorff and compact.
\end{proposition}
\begin{proof}
Obviously, $\Omega$ is Hausdorff since $\omega^*$-topology is Hausdorff. Consider $\Omega^\prime := \Omega \cup \{0\}$. If $\chi_\alpha \rightarrow f$ in $\omega^*$-topology, then obviously $f$ preserves multiplication (but it might become zero), so $\Omega^\prime$ is a closed subset of the unit ball in $A^*$. Now it's the consequence of Banach-Alaoglu theorem that $\Omega^\prime$ is compact. Being a closed subset of a compact Hausdorff space, we see that $\Omega$ is locally compact and Hausdorff. In case $A$ is unital, $0$ is an isolated point of $\Omega^\prime$, for if there was a net $\chi_\alpha \in \Omega$ such that $\chi_\alpha \rightarrow 0$, then $1 = \chi_\alpha(1) \rightarrow 0$, which is a contradiction, and thus $\Omega$ is compact.
\end{proof}
The beauty of the result and the proof are mesmerizing, so I couldn't resist working out the details. Here I'd like to record a sketch for the unital case (the non-unital has to come from the unital by the process of adjoining an identity). One can find a full proof in \cite{arveson}.
\begin{proof}[Sketch of the proof of the 1st G-F theorem.]
First of all, in case of $C^*$-algebras it is automatic that every character preserves the $\ast$-structure. This fact implies that $\Gamma_A$ is a unital $\ast$-homomorphism. Next, one shows that the spectrum $\sigma(a)$ of any $a \in A$ coincides with the range of $\hat{a}$. Indeed, $\lambda \in \sigma(a)$ if and only if $a-\lambda$ is not invertbile, if and only if $a-\lambda$ belongs to some maximal ideal; there is a $1-1$ correspondence between maximal ideals and characters in unital commutative Banach algebras, so we find $\chi$ such that $\chi(a-\lambda) = \lambda$, i.e., $\hat{a}(\chi) = \lambda$. A consequence of this is that the spectral radius $r(a)$ of any $a$ coincides with the norm of $\hat{a}$. Now, if $a$ is self-adjoint, then $\|a\| = r(a) = \|\hat{a}\|$, which means that $\Gamma_A$ works as an isometry on self-adjoint elements. If $a \in A$ is an arbitrary one, then we use the $C^*$-structure and the fact that $a^*a$ is self-adjoint:
\[
\|a\|^2 = \|a^* a\| = \|\hat{a}^* \hat{a}\| = \|\hat{a}\|^2.
\]
Thus $\Gamma_A$ is an isometric embedding. Its image is a closed subalgebra and contains the identity of $C(\Omega)$. For surjectivity, one applies the Stone-Weierstrass theorem: the functions $\hat{a}$ separate the points (for two different $\chi_1 \neq \chi_2$, just take any $a \in \Ker \chi_1 \setminus \Ker \chi_2$, and then $0 = \hat{a}(\chi_1) \neq \hat{a}(\chi_2)$).
\end{proof}

\subsubsection{Gelfand-Naymark: non-commutative case}
In this section, I describe the Gelfand-Naymark-Segal construction that is used to show that any $C^*$ algebra can be isometrically represented in some Hilbert space. The construction relies on the notions of states and pure states. I assume everywhere that there's a fixed unital $C^*$-algebra $A$. A good source for the relevant results is \cite{arveson}.
\begin{definition}
A state $f$ is a positive linear functional $f$ (i.e., $f(z^*z) \geq 0$ for any $z$) that is normalized at the unit: $f(1) = 1$. 
\end{definition}
One can show that states form a convex $\omega^*$-compact set: it coincides with all bounded linear functionals whose norm is $1$ and which is achieved at the identity. By Krein-Millman theorem, this set is the closed convex hull of so-called \emph{extreme points}\footnote{I.e., points that are not interior points of intervals lying inside that set.}. These extreme points are called \emph{pure states}. For any state $f$, one can find a representation $\pi$ in some Hilbert space $H$, and a vector $\xi \in H$ such that 
\[
f(x) = (\pi(x)\xi,\xi).
\]
Moreover, $\xi$ can be chosen in such a way that the span of $\{\pi(x)\xi \ | \ x \in A\}$ is dense in $H$. The construction also tells us that $\pi$ is irreducible if and only if $f$ is a pure states. The steps to find $\pi$ are the following:

We define $\pi(x)$ for every $x \in A$ as the multiplication by $x$ on the left: $\pi(x)(y) = xy$. Since the chosen state $f$ is positive, it yields a positive sesquilinear form $(x,y) : = f(y^*x)$ on $A$. The form has a kernel $N:= \{(x,x) = 0\}$, so the quotient $A/N$ is a vector space with an inner product. It turns out that $N$ is also a left ideal with respect to the multiplication, hence every $\pi(x)$ lifts to $A/N$. Now, simply complete $A/N$ and extend each $\pi(x)$ to a bounded linear operator on the obtained Hilbert space. The work to be done is to show that every $\pi(x)$ is bounded. But this turns out to be true. The vector $\xi$ is then $\xi : = 1 +N$. If in the end we do not obtain that $\Sp \{\pi(x)\xi \ | \ x\in A\}$ is dense, simply restrict the representation to this subspace.

Next, a series of propositions in \cite{arveson} tells us that for any self-adjoint $x \in A$, we can find a pure state $f$ such that $f(x) = \|x\|$. This makes us think that instead of constructing representations through pure states, we can actually start with elements of $A$. A corollary of this is that for every element $z \in A$, there's an irreducible representation $\pi$ and a vector $\xi$ in its Hilbert space such that $\|\pi(z)\xi\| = \|z\|$. This is enough to prove the Gelfand-Naymark theorem:
\begin{theorem}
(Gelfand-Naymark) For any unital $C^*$-algebra $A$, there's an isometric representation in some Hilbert space.
\end{theorem}
\begin{proof}
As we discussed above, for every non-zero $z \in A$ we pick a representation $\pi_z$ such that $\|\pi_z(z)\xi_z\| = \|z\|$. The direct some of all of these representations is then injective. It's also a result of $C^*$-algebra homomorphisms that injectivity implies that $\pi$ is isometric.
\end{proof}

\subsubsection{Properties of AF algebras (not finished)}
\begin{definition}
A (unital) $C^*$-algebra $A$ is called \emph{approximately finite-dimensional} if $A$ is an inductive limit of a sequence of finite-dimensional (unital) $C^*$-algebras.
\end{definition}
I'd like to record some interesting properties of such algebras. They may not be important for our purposes, though. An example of an AF algebra appearing in these notes is the space of observables attached to an infinite sublattice when a Hilbert space at a single site is finite-dimensional.
\begin{proposition} (see \cite{bratteli})
Let $A$ be a unital $C^*$-algebra. Then $A$ is an AF-algebra if and only if the following two conditions are fullfilled:
\begin{enumerate}[(i)]
\item $A$ is separable;
\item If $x_1,\ldots,x_n \in A$ and $\varepsilon > 0$, then there exist a finite-dimensional $C^*$-subalgebra $B \subseteq A$ and elements $y_1,\ldots,y_n \in B$ such that $\|x_i-y_i\| < \varepsilon$, $i=1,\ldots,n$.
\end{enumerate}
Furthermore, if $A$ is AF, and $A_1$ is a finite-dimensional $C^*$-subalgebra of $A$, there exists an increasing sequence $A_2 \subseteq A_3 \subseteq \cdots $ of finite-dimensional $C^*$-subalgebras such that $A_1 \subseteq A_2$ and $A = \bigcup_{i}A_i$.
\end{proposition}
Some aspects of the statement are not clear to me, and if needed, can delve into: so, the closure is not taken in the second bullet, is this right?

A couple of interesting results on pure states:
\begin{proposition}(see \cite{bratteli})
Let $A$ be an AF-algebra and let $\omega_1$ and $\omega_2$ be pure states of $A$ such that the associated representations $\pi_1$ and $\pi_2$ are faithful. Then there exists an automorphism $\alpha$ of $A$ such that $\omega_1 = \omega_2 \circ \alpha$.
\end{proposition}
The next proposition is basically saying that a state is pure iff its restriction to each finite-dimensional subalgebra is pure.
\begin{proposition}(see \cite{bratteli})
Let $A$ be an AF-algebra and let $\omega$ be a state of $A$ such that the associated representation is faithful. Then $\omega$ is pure if and only if there exists an increasing subsequence $A_n$ of finite-dimensional $\ast$-subalgebras of $A$ all containing the identity and such that $A = \varinjlim A_n$ and $\omega | A_n$ is pure for all $n$.
\end{proposition}

\subsection{Hilbert-Schmidt operators}
The results on Hilbert-Schmidt operators can be found in a concise form in \cite{conway} on page 268.

Let $H$ be an infinite-dimensional Hilbert space and $\mathfrak A:= \End(H)$ be the space of bounded linear endomorphisms. If $e_1,\ldots,e_n,\ldots$ is an orthonormal basis of $H$, for $A \in \mathfrak A$ set
\[
\|A\|_2 := \sqrt{\sum_i \|Ae_i\|^2}.
\]
It turns out that $\|A\|_2$ does not depend on the choice of the orthonormal basis. The operator $A$ is called a \emph{Hilbert-Schmidt operator} if $\|A\|_2 < \infty$. Denote the corresponding space as $\mathfrak A_2$. These operators satisfy the following properties:
\begin{enumerate}[(a)]
\item $\|A\| \leq \|A\|_2$;
\item If $T \in \mathfrak A$ and $A \in \mathfrak A_2$, then
\[
\|TA\|_2 \leq \|T\| \|A\|_2, \ \ \|AT\|_2 \leq \|A\|_2 \|T\|;
\]
\item $\|A\|_2=\|A^*\|_2$;
\item Algebraically, $\mathfrak A_2$ is a two-sided ideal of $\mathfrak A$ (non-closed in the operator norm topology in infinite-dimensional case);
\item The subspace of finite-rank operators is contained in $\mathfrak A_2$ and is dense there;
\item $A \in \mathfrak A_2$ iff $|A|:= \sqrt{A^*A} \in \mathfrak A_2$. In this case, $\|A\|_2 = \||A|\|_2$;
\item Hilbert-Schmidt operators are compact. Moreover, if $\lambda_1,\ldots,\lambda_n,\ldots$ are eigenvalues of $|A|$ (each repeated as many times as its multiplicity), then $|A| \in \mathfrak A_2$ if and only if $\sum_{n=1}^\infty \lambda_n^2 < \infty$. In this case, $\|A\|_2 = \sqrt{\sum_{n=1}^\infty \lambda_n^2}$.
\end{enumerate}
\subsection{Quantum physics}
\subsubsection{Spin}
I read a chapter on spins in Landau's book \cite{landau}. Here I record what I understand about spins. So, the \emph{spin} of a particle is something that behaves like a classical angular momentum (at least, it has some properties of that). If $\psi(x,y,z)$ is a wave function that depends on three coordinates, then we'd like to include a variable $\sigma$, which corresponds to the spin, and the wave function then depends on four variables: $\psi(x,y,z;\sigma)$. We have a spin operator $S = (S_x,S_y,S_z)$ that we can apply to the wave function. As Landau says, we apply it somehow straight to the variable $\sigma$. What's the meaning of $S\psi$? I guess, this means that we conduct a measurement of the spin of a particle that's in the state $\psi$. There's an heuristic reasoning, which I don't understand, but which yields the following commutation realtions among components of $S$:
\[
\{S_y,S_z\} = iS_x, \ \ \{S_z,S_x\} = iS_y, \ \ \{S_x,S_y\} = iS_z,
\]
where the bracket denotes, I guess, the anti-commutator.
They also derive
\[
S^2 = s(s+1),
\]
where $s$ is the least upper bound of eigenvalues of $S_z$ (then $-s$ is the greatest lower bound of the eigenvalues). From this they derive that $s \in \frac{1}{2}\mathbb{Z}$. As I understand, that relation means
\[
S_x^2 + S_y^2 + S_z^2 = s(s+1) I,
\]
where $I$ is the identity operator, though it is not clear why we have such an equation. Depending on $s$, the components are realized as square matrices of different sizes. If $s = 1/2$, then the components are $2 \times 2$ matrices (Pauli matrices). For $s = 1$, they are $3 \times 3$ matrices. One can find a relation between $s$ and their sizes. Also, I don't think that the relation between $S^2$ and $s$ can be derived from the commutation relations between components of $S$.

\subsection{Perturbation theory}
I mention a few results from Rellich's \cite{rellich} book.
\begin{proposition}\label{p:conv_le}
Let $A$ and $B$ be Hermitian operators on a finite-dimensional space, and consider an operator $A + \varepsilon B$ for some $\varepsilon \in \mathbb R$. Let $\lambda(\varepsilon)$ be the least eigen-value of $A+\varepsilon B$. Then $\lambda$ is a concave function of $\varepsilon$.
\end{proposition}
There's a typo in the Rellich's book. The least eigen-value is concave, not convex!
\begin{proof}
Recall that a function is convex iff its epigraph is convex. For $-\lambda(\varepsilon)$, we basically show that the epigraph is the intersection of a family of half-subspaces, which is convex.

So, fix $\varepsilon_0$ and let $f_0$ be a normalized eigen-vector that corresponds to $\lambda(\varepsilon_0)$. Then $(f_0,Af_0) + \varepsilon (f_0, Bf_0) = \lambda(\varepsilon_0)$. For any other normalized vector $f$, the property of being the least eigen-value also yields
\[
(f,Af) + \varepsilon (f, Bf) \geq \lambda(\varepsilon)
\]
for any $\varepsilon > 0$. In particular, for $a = (f_0,Af_0)$, $b = (f_0,Bf_0)$ and any $\varepsilon > 0$
\[
a + \varepsilon b \geq \lambda(\varepsilon).
\]
So, we have a line $\varepsilon \mapsto a+\varepsilon b$ intersects the graph of $\lambda$ at $\varepsilon = \varepsilon_0$ and which defines a half-subspace that contains the graph of $\lambda$. Varying $\varepsilon_0$, we obtain a family of such lines, which intersect into the epigraph of $-\lambda$, which henceforth convex.
\end{proof}

The following theorem is also from \cite{rellich} and is of special interest to us:
\begin{theorem}\label{thm:pert}
Let $I$ be an open interval and $A : I \rightarrow \End(V)$ be a $C^1$-family of Hermitian operators on a finite-dimensional space $V$. Assume that $A^\prime : I \rightarrow \End(V)$ is also a Hermitian family. Then there exist a family of $C^1$ functions $\lambda_i : I \rightarrow \mathbb R$ and a family of vectors $f_i : I \rightarrow V$ such that $\lambda_i \leq \lambda_{i+1}$, $\{f_i(\varepsilon)\}$ is orthonormal for every $\varepsilon \in I$, and $A(\varepsilon) f_i(\varepsilon) = \lambda_i(\varepsilon)f_i(\varepsilon)$.
\end{theorem}
Note that I do not claim that the family of vectors is $C^1$, for this is not explicitly stated in \cite{rellich}. 
I found it in the book by Kato \cite{kato}, pp. 121-122, but it's true only if we have a holomorphic family. On p. 111 of Kato's book there is an example of a $C^{\infty}$-family of Hermitian matrices on a real line such that there are no continuous choices of eigen-vectors on $\mathbb R$. In our case (Lattice $\mathbb Z_n$-QED 1+1), the Hamiltonian is holomorphic, but for complex values of $m$ it's not Hermitian, so the theorem is not applicable. And if it was, we would get a contradiction with the continuity of the ground state. In case $N=3$ one can easily see that that there's no continuous choice of the ground state.
\begin{theorem} (\cite{kato}, p. 121)
Let $D \subseteq \mathbb C$ be a domain in $\mathbb C$ that intersects the real axis. Let $A : D \rightarrow \Mat_{n\times n}(\mathbb C)$ be a holomorphic family of Hermitian matrices. Then there's a choice of orthonormal family of eigen-vectors of $A$ that is holomorphic on $D \cap \mathbb R$.
\end{theorem}

\subsection{Gershgorin theorem}
I'd like to adjust the following theorem for our situation. It might help us to determine the non-degeneracy of the ground state. A reference is Horn's book on Matrix Analysis \cite{horn}. I've read the theorems in the chapter on locating eigen-values and don't think that anything else could be of interest to us.

Let $A = (a_{ij})_{i,j=1}^n$ be a matrix with complex entries. Define $R_i:=R_i(A) := \sum_{j\neq i} |a_{ij}|$. A \emph{Gershgorin disc} is the closed disc $D(a_{ii},R_i)$ on the complex plane with the center at $a_{ii}$ and radius $R_i$.
\begin{theorem}
All eigenvalues of $A$ are contained in the union of Gershgorin discs of $A$. Moreover, if $k$ discs are disjoint from the other $n-k$, then exactly $k$ eigen-values of $A$ (counting multiplicities) are contained in the union of $k$ discs.
\end{theorem}
\begin{proof}
Let $\lambda$ be an arbitrary eigen-value of $A$, and let $x\in \mathbb C^n$ be an eigen-vector. We can choose $x$ in such a way that $x_i = 1$ for some $i$, and for the rest $|x_j| \leq 1$ (just pick any $x$ and divide by $\max_{1\leq j\leq n}|x_j|$). Now, by the very definition of $x$,
\[
\sum_{j=1}^n a_{ij}x_j = \lambda
\]
or
\[
\sum_{j \neq i} a_{ij}x_j + a_{ii} = \lambda.
\]
It follows from the triangle inequality that
\[
|\lambda-a_{ii}| \leq \sum_{j \neq i} |a_{ij}x_j| \leq R_{i}.
\]
Thus $\lambda \in D(a_{ii}, R_i)$.

Let's prove the second part. WLOG, assume that the union of the first $k$ discs is disjoint from the other $n-k$. Write $A = B + D$, where $D$ is the diagonal of $A$. Define a continuous family of matrices $A_{\varepsilon}:= \varepsilon B + D$, $\varepsilon \in [0,1]$. Notice that $R_i(A_{\varepsilon}) = \varepsilon R_i(A)$ and the Gershgorin discs for the whole family have the same centers. Therefore, for any $\varepsilon \in [0,1]$, the first $k$ discs are disjoint from the other $n-k$. Let $\Gamma$ be a simple smooth curve that encompasses the first $k$ discs, and let $p_{\varepsilon}$ be the characteristic polynomial of $A$. By the argument principle, the number of roots of $p_{\varepsilon}$ (counting multiplicites) inside $\Gamma$ is 
\[
N_{\varepsilon} := \frac{1}{2\pi i}\int_{\Gamma} \frac{p^\prime_{\varepsilon}(z)}{p_{\varepsilon}(z)}\, dz.
\]
Note that $N_{\varepsilon}$ is a continuous function of $\varepsilon$. Since it's integer valued and $N_0 = k$, we conclude that $N_1 = k$ as well. Thus there are exactly $k$ eigen-values in the union of the first $k$ discs.
\end{proof}